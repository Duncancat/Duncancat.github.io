<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Publications – Duncancat</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>

<nav class="navbar">
  <div class="nav-container">
    <a href="index.html" class="site-name">Duncancat</a>
    <div class="nav-links">
      <a href="index.html">About</a>
      <a href="publications.html">Publications</a>
    </div>
  </div>
</nav>

<div class="main">
  <aside class="sidebar">
    <div class="profile-pic">
      <img src="duncan.jpg" alt="Duncan Deng">
    </div>
    <h2>Duncan Deng</h2>
    <p>High school Affiliated to Renmin University | AI Executive Consulting</p>
    <p>Email: duncandeng114@gmail.com</p>
    <p>GitHub: <a href="https://github.com/Duncancat" target="_blank" class="sidebar-link">github.com/Duncancat</a></p>
  </aside>

  <section class="content">
    <h1 style="font-size: 28px; line-height: 1.3; margin-bottom: 20px;">Mechanics-Aware LLM Orchestrator for Human–Robot Bimanual Co-Manipulation</h1>

    <div class="pub-item">
      <p> Saien Deng, David Scott Lewis, Workshop on Intelligent Robotics for Manipulation and Workshop on Bimanual Manipulation: Advancing Human-Humanoid Interaction and Collaboration
      at International Conference on Intelligent Robots and Systems (IROS), 2025</p><p>
         <a href="" class="publish-link">pdf</a> · 
         <a href="" class="publish-link">poster</a>
      </p>
    </div>

    <div class="pub-item">
      <p>Bimanual manipulation in human-robot teams requires coordinated motion and careful regulation of interaction forces.
        Classical control approaches—from hybrid position/force control to impedance control—provide a foundation for safe 
        contact handling, but dynamically tuning their parameters for diverse tasks and unpredictable human partners remains 
        challenging. Meanwhile, Large Language Models (LLMs) are emerging as high-level reasoning engines in robotics, showing 
        promise in complex task planning. This paper proposes the “Mechanics-Aware LLM Orchestrator,” a novel conceptual 
        architecture that bridges advanced reasoning and low-level mechanical control for fluent human-robot co-manipulation. 
        We detail a system where an LLM dynamically selects dual-arm coordination strategies, impedance parameters (stiffness/damping), 
        and internal-force targets in real time. This is achieved by issuing API calls (e.g., set_impedance(), choose_mode(), 
        set_internal_force_bounds()) to a hybrid operational-space control stack. The architecture combines an LLM “oracle” 
        reasoning about contact mechanics, manipulability, and task context at 5–10 Hz, with a task-space impedance controller 
        enforcing those commands at 1 kHz. We outline how this orchestrator can yield safer, more fluent teamwork than fixed-gain 
        baselines in scenarios like cooperative carrying and assembly. We discuss prompt engineering techniques, including 
        chain-of-thought for stability considerations, and present a concrete MVP implementation plan. This framework charts a 
        path toward foundation models that not only plan what to do, but continuously shape how to do it in physical collaboration.</p>
    </div>
  </section>
</div>

</body>
</html>
